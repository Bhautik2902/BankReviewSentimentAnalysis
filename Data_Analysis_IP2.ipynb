{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Sentiment Analysis of Canadian Banks' reviews: Insights for Informed Decision-Making\n",
    "\n",
    "This Jupyter notebook is dedicated to the comprehensive analysis of customer sentiments towards the top five Canadian banks. The primary goal is to uncover and present key insights that potential customers and stakeholders can use to make informed decisions regarding their banking choices. The notebook includes detailed steps for data cleaning to ensure the accuracy and reliability of the analysis. Subsequent sections perform rigorous sentiment analysis, leveraging natural language processing techniques to interpret and quantify customer reviews and feedback. The final outputs are visualized through graphs and charts, providing a clear depiction of sentiment trends and patterns across different banks and services, empowering users with actionable financial insights.\n",
    "\n"
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T00:20:39.319350Z",
     "start_time": "2024-09-27T00:20:16.795062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel('./data/Merged_CSV_excel_file.xlsx', engine='openpyxl')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n"
   ],
   "id": "fbc121e30a2defb3",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T00:20:48.973680Z",
     "start_time": "2024-09-27T00:20:48.934752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rows_to_delete = ['Country', 'Version', 'Author', 'Translated title', 'Translated review', 'User', 'Tags', 'Categories', 'Updated', 'Semantic Tags', 'Semantic Categories', 'Semantic Sentiment', 'Notes', 'Likes', 'Dislikes', 'Link', 'Permalink', 'AF Link', 'Device Name', 'VersionCode', 'OS']\n",
    "\n",
    "df.drop(rows_to_delete, axis=1, inplace=True)\n",
    "\n",
    "print(df.head())\n",
    "\n"
   ],
   "id": "3b72d84d0789c93f",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T00:20:52.942946Z",
     "start_time": "2024-09-27T00:20:52.723790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Update the 'Submission date' column to contain only the date part (before 'T')\n",
    "df['Submission date'] = df['Submission date'].str.split('T').str[0]\n",
    "\n",
    "display(df)"
   ],
   "id": "ae025f0dff5da189",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T00:20:56.784666Z",
     "start_time": "2024-09-27T00:20:56.729558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_removed_columns_and_formatted_date = df.copy()\n",
    "display(df_removed_columns_and_formatted_date)\n",
    "\n",
    "print(df['AppID'][4] == \"com.bmo.mobile\")"
   ],
   "id": "ff09ecef1cf5aff8",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T00:21:12.407515Z",
     "start_time": "2024-09-27T00:21:12.375505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to map AppID to AppName\n",
    "def update_app_name(app_id):\n",
    "    if app_id == \"com.bmo.mobile\":\n",
    "        return \"bmo_GooglePlay\"\n",
    "    elif app_id == \"com.cibc.android.mobi\":\n",
    "        return \"cibc_GooglePlay\"\n",
    "    elif app_id == \"ca.bnc.android\":\n",
    "        return \"nbc_GooglePlay\"\n",
    "    elif app_id == \"com.rbc.mobile.android\":\n",
    "        return \"rbc_GooglePlay\"\n",
    "    elif app_id == 407597290:\n",
    "        return \"rbc_AppStore\"\n",
    "    elif app_id == \"com.scotiabank.banking\":\n",
    "        return \"scotia_GooglePlay\"\n",
    "    elif app_id == \"com.td\":\n",
    "        return \"td_GooglePlay\"\n",
    "    elif app_id == 358790776:\n",
    "        return \"td_AppStore\"\n",
    "    else:\n",
    "        return df['AppName']  # Retain existing AppName if no match\n",
    "\n",
    "# Apply the function to the 'AppID' column and update the 'AppName' column\n",
    "df['AppName'] = df['AppID'].apply(update_app_name)\n",
    "\n",
    "display(df)"
   ],
   "id": "1d56a7e76b0fd5bc",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T00:23:48.706182Z",
     "start_time": "2024-09-27T00:23:26.444159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "set_up_AppID_and_AppName = df.copy()\n",
    "display(set_up_AppID_and_AppName)\n",
    "\n",
    "# df.to_excel('./data/cleaned_xl_file.xlsx', index=False)\n"
   ],
   "id": "c7005366c2d476c1",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Processing cleaned data",
   "id": "89c16700257c9d75"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T16:42:09.880930Z",
     "start_time": "2024-10-03T16:41:58.288341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_excel('./data/cleaned_xl_file.xlsx', engine='openpyxl')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n"
   ],
   "id": "ce438e0501db43a1",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T20:12:19.195320Z",
     "start_time": "2024-10-02T20:11:58.450241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Remove all rows where the 'language' column is not 'en' or 'fr'\n",
    "# df_filtered = df[df['Review Language'].isin(['en', 'fr'])]\n",
    "df_filtered = df[(df['Review Language'].isin(['en', 'fr'])) & (df['Review Language'].notna()) & (df['Review Language'].str.strip() != '')]\n",
    "\n",
    "# Create a pie chart categorized by language\n",
    "language_counts = df_filtered['Review Language'].value_counts()\n",
    "print(language_counts)\n",
    "\n",
    "# Plot pie chart\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.pie(language_counts, labels=language_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Distribution of Languages (en and fr)')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures the pie is drawn as a circle.\n",
    "plt.show()\n",
    "display(df_filtered)\n",
    "\n",
    "# df_filtered.to_excel('./data/cleaned_xl_file_en_fr.xlsx', index=False)\n"
   ],
   "id": "8fbbccfa62eac8f7",
   "execution_count": 29,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T20:13:02.022937Z",
     "start_time": "2024-10-02T20:13:01.837753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Group by the substring before the underscore in 'AppName'\n",
    "analyze_df = df_filtered.copy()\n",
    "analyze_df['AppGroup'] = analyze_df['AppName'].str.split('_').str[0]\n",
    "\n",
    "# Get the count for each group\n",
    "group_counts = analyze_df['AppGroup'].value_counts()\n",
    "\n",
    "# Function to show both percentage and count\n",
    "def func(pct, allvalues):\n",
    "    absolute = int(pct/100.*sum(allvalues))\n",
    "    return f\"{pct:.1f}%\\n({absolute:d})\"\n",
    "\n",
    "# Plot donut chart with category labels, percentages, and counts\n",
    "plt.figure(figsize=(6, 6))\n",
    "wedges, texts, autotexts = plt.pie(\n",
    "    group_counts, \n",
    "    labels=group_counts.index,  # Category labels only\n",
    "    autopct=lambda pct: func(pct, group_counts),  # Show percentage and count\n",
    "    startangle=90, \n",
    "    wedgeprops={'width': 0.3},  # Makes it a donut chart\n",
    "    pctdistance=0.85,  # Position the percentages closer to the center\n",
    "    textprops=dict(color=\"black\"),  # Set text color for the category labels\n",
    "    labeldistance=1.65  # Set distance for the category labels outside the chart\n",
    ")\n",
    "\n",
    "# Customize percentage and count text appearance inside slices\n",
    "for autotext in autotexts:\n",
    "    autotext.set_fontsize(10)  # Set font size of percentages and counts\n",
    "    autotext.set_color('white')  # Set color of percentage text\n",
    "\n",
    "# Set title for the chart\n",
    "plt.title('AppName Group Distribution')\n",
    "\n",
    "# Equal aspect ratio ensures that pie is drawn as a circle\n",
    "plt.axis('equal')\n",
    "\n",
    "# Display the chart\n",
    "plt.show()"
   ],
   "id": "8579c69273949fd8",
   "execution_count": 31,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T20:13:10.169460Z",
     "start_time": "2024-10-02T20:13:10.164518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "row_count = df_filtered.shape[0]\n",
    "\n",
    "print(row_count)"
   ],
   "id": "aaacbbb6fa6fc304",
   "execution_count": 33,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T20:13:50.445303Z",
     "start_time": "2024-10-02T20:13:50.435278Z"
    }
   },
   "cell_type": "code",
   "source": "display(df_filtered)",
   "id": "4894c19904db0a4d",
   "execution_count": 34,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T16:21:32.454767Z",
     "start_time": "2024-10-03T16:21:31.974296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Creating batches from entire dataset\n",
    "import numpy as np\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 20000\n",
    "\n",
    "# Split DataFrame into batches of 20,000 rows\n",
    "batches = np.array_split(df_filtered, len(df_filtered) // batch_size + 1)"
   ],
   "id": "96158b58817a5de4",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T22:30:14.133202Z",
     "start_time": "2024-10-02T22:30:14.127037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "subbatch = batches[0].head(100)\n",
    "count_fr = subbatch[subbatch['Review Language'] == 'fr'].shape[0]\n",
    "\n",
    "print(count_fr)"
   ],
   "id": "302d2d63ba29cf5a",
   "execution_count": 45,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T20:46:38.730380Z",
     "start_time": "2024-10-02T20:46:38.696176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "import sentencepiece as spm\n",
    "\n",
    "# Load the pre-trained MarianMT model for translating French to English\n",
    "model_name = 'Helsinki-NLP/opus-mt-fr-en'\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "# Function to translate French reviews to English\n",
    "def translate_to_english(text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    # Generate the translated tokens\n",
    "    translated_tokens = model.generate(**inputs)\n",
    "    # Decode the tokens to get the translated string\n",
    "    translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "    return translated_text\n",
    "\n",
    "# Apply translation only where 'Review Language' is 'fr'\n",
    "batches[0]['Review'] = batches[0].apply(\n",
    "    lambda row: translate_to_english(row['Review']) if row['Review Language'] == 'fr' else row['Review'], axis=1\n",
    ")\n",
    "\n",
    "display(batches[0])"
   ],
   "id": "383e6809952c43e4",
   "execution_count": 42,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#Further steps",
   "id": "d8f8cac98fc0c958"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T15:59:08.147668Z",
     "start_time": "2024-10-02T15:59:03.837684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the pre-trained RoBERTa model for sentiment analysis\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Create a sentiment analysis pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Function to analyze sentiment using the RoBERTa model\n",
    "def analyze_sentiment(review_text):\n",
    "    result = sentiment_pipeline(review_text)[0]                                                                                                             \n",
    "    label = result['label']\n",
    "    # Map the RoBERTa model's output to 'positive', 'negative', or 'neutral'\n",
    "    if label == 'LABEL_2':  # Positive sentiment\n",
    "        return 'positive'\n",
    "    elif label == 'LABEL_0':  # Negative sentiment\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Assuming df is your existing dataframe with a 'Review' column\n",
    "# Apply the sentiment analysis to the 'Review' column and create a new column 'Review sentiment'\n",
    "df_filtered['Review sentiment'] = df_filtered['Review'].astype(str).apply(analyze_sentiment)\n",
    "\n",
    "display(df_filtered)\n"
   ],
   "id": "1fa512ce235d73ae",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T10:18:47.506163Z",
     "start_time": "2024-09-30T10:18:47.500706Z"
    }
   },
   "cell_type": "code",
   "source": "# Converting all reviews to english",
   "id": "b0ec15f1c39d8965",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T10:52:40.862019Z",
     "start_time": "2024-09-30T10:23:07.370895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "# Initialize the Google Translator\n",
    "translator = Translator()\n",
    "\n",
    "# Translate the text where 'Review Language' is 'fr'\n",
    "df_filtered.loc[df['Review Language'] == 'fr', 'Review'] = df_filtered.loc[df['Review Language'] == 'fr', 'Review'].apply(lambda x: translator.translate(x, src='fr', dest='en').text)\n",
    "\n",
    "display(df_filtered)"
   ],
   "id": "f7b7d7cd235e09",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "458b4ac3a4295957",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
